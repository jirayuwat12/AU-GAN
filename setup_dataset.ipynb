{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "DATASET_PATH = './datasets'\n",
    "\n",
    "for folder in os.listdir(DATASET_PATH):\n",
    "    folder_path = os.path.join(DATASET_PATH, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        shutil.rmtree(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDD100K dataset\n",
    "- Download dataset from [BDD100K](https://bdd-data.berkeley.edu/portal.html#download)\n",
    "- Move downloaded zip file to the same folder as this notebook\n",
    "- Set the constant parameter\n",
    "- This part of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for extract zip file\n",
    "LABEL_ZIP_PATH = './bdd100k_labels_release.zip'\n",
    "DATASET_ZIP_PATH = './bdd100k_images_10k.zip'\n",
    "\n",
    "\n",
    "UNZIP_PATH = './raw_unzip'\n",
    "# for move images to train and test folder\n",
    "TRAIN_LABEL_PATH = os.path.join(UNZIP_PATH, 'bdd100k', 'labels', 'bdd100k_labels_images_train.json')\n",
    "VAL_LABEL_PATH = os.path.join(UNZIP_PATH, 'bdd100k', 'labels', 'bdd100k_labels_images_val.json')\n",
    "SOURCE_PATH = os.path.join(UNZIP_PATH, 'bdd100k', 'images', '10K')\n",
    "DATASET_NAME = 'BDD100K'\n",
    "TRAIN_TEST_SPLIT_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract zip file\n",
    "with zipfile.ZipFile(LABEL_ZIP_PATH, 'r') as zip_ref:\n",
    "    zip_ref.extractall(UNZIP_PATH, )\n",
    "with zipfile.ZipFile(DATASET_ZIP_PATH, 'r') as zip_ref:\n",
    "    zip_ref.extractall(UNZIP_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move image to dataset folder\n",
    "- folder `A` is night image\n",
    "- folder `B` is day image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label json file\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear dataset folder\n",
    "if os.path.exists(os.path.join('datasets', DATASET_NAME)):\n",
    "    shutil.rmtree(os.path.join('datasets', DATASET_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset structure folder\n",
    "for path in [\n",
    "    'datasets',\n",
    "    os.path.join('datasets', DATASET_NAME),\n",
    "    os.path.join('datasets', DATASET_NAME, 'trainA'),\n",
    "    os.path.join('datasets', DATASET_NAME, 'trainB'),\n",
    "    os.path.join('datasets', DATASET_NAME, 'testA'),\n",
    "    os.path.join('datasets', DATASET_NAME, 'testB')\n",
    "]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = json.load(open(TRAIN_LABEL_PATH))\n",
    "val_label = json.load(open(VAL_LABEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label = dict()\n",
    "for label in train_label:\n",
    "    image_label[label['name']] = label['attributes']\n",
    "for label in val_label:\n",
    "    image_label[label['name']] = label['attributes']\n",
    "del train_label, val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test - fffc7bba-f05de9f5.jpg: 100%|██████████| 2000/2000 [00:04<00:00, 471.59image/s]\n",
      "train - ff3da814-c3463a43.jpg: 100%|██████████| 7000/7000 [00:41<00:00, 167.50image/s]\n",
      "val - ff7b98c7-3cb964ac.jpg: 100%|██████████| 1000/1000 [00:02<00:00, 480.08image/s]\n"
     ]
    }
   ],
   "source": [
    "for subdir in os.listdir(SOURCE_PATH):\n",
    "    curr_path = os.path.join(SOURCE_PATH, subdir)\n",
    "\n",
    "    looper = tqdm(os.listdir(curr_path), desc=subdir, unit='image')\n",
    "    for image in looper:\n",
    "        looper.set_description(f'{subdir} - {image}')\n",
    "        looper.refresh()\n",
    "\n",
    "        if image not in image_label:\n",
    "            continue\n",
    "        \n",
    "        label = image_label[image]\n",
    "        if label['timeofday'] == 'daytime':\n",
    "            if random.random() < TRAIN_TEST_SPLIT_RATIO:\n",
    "                shutil.copy(os.path.join(curr_path, image), os.path.join('datasets', DATASET_NAME, 'trainB', image))\n",
    "            else:\n",
    "                shutil.copy(os.path.join(curr_path, image), os.path.join('datasets', DATASET_NAME, 'testB', image))\n",
    "        elif label['timeofday'] == 'night':\n",
    "            if random.random() < TRAIN_TEST_SPLIT_RATIO:\n",
    "                shutil.copy(os.path.join(curr_path, image), os.path.join('datasets', DATASET_NAME, 'trainA', image))\n",
    "            else:\n",
    "                shutil.copy(os.path.join(curr_path, image), os.path.join('datasets', DATASET_NAME, 'testA', image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear unused folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove raw unzip folder\n",
    "shutil.rmtree(UNZIP_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aj.'s dataset (AJDATASET01)\n",
    "\n",
    "- from VDO `2021_0607_184742_013.MOV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup constant parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_POOL_PATH = 'E:/indiv_vdo/extracted/image_pool/'\n",
    "IMAGE_INFO_DICT_PATH = 'E:/indiv_vdo/extracted/dict/info_dict.pkl'\n",
    "\n",
    "TARGET_DATASET_PATH = 'E:/indiv_vdo/datasets'\n",
    "DATASET_NAME = 'AJDATASET01'\n",
    "\n",
    "TRAIN_TEST_SPLIT_RATIO = 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move image to dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info_dict = pickle.load(open(IMAGE_INFO_DICT_PATH, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate dataset structure folder\n",
    "if os.path.exists(os.path.join(TARGET_DATASET_PATH, DATASET_NAME)):\n",
    "    shutil.rmtree(os.path.join(TARGET_DATASET_PATH, DATASET_NAME))\n",
    "for path in [\n",
    "        TARGET_DATASET_PATH,\n",
    "        os.path.join(TARGET_DATASET_PATH, DATASET_NAME),\n",
    "        os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'trainA'),\n",
    "        os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'trainB'),\n",
    "        os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'testA'),\n",
    "        os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'testB')\n",
    "    ]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "copy image: 100%|██████████| 264/264 [00:00<00:00, 608.30image/s]\n"
     ]
    }
   ],
   "source": [
    "# copy image from image pool to dataset folder\n",
    "looper = tqdm.tqdm(os.listdir(IMAGE_POOL_PATH), desc='copy image', unit='image')\n",
    "for image_name in looper:\n",
    "    if image_name in image_info_dict:\n",
    "        image_info = image_info_dict[image_name]\n",
    "        if image_info['vdo_name'] != '2021_0607_184742_013.MOV':\n",
    "            continue\n",
    "        if image_info['day_night'] == 'day':\n",
    "            if random.random() < TRAIN_TEST_SPLIT_RATIO:\n",
    "                shutil.copy(os.path.join(IMAGE_POOL_PATH, image_name), os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'trainB', image_name))\n",
    "            else:\n",
    "                shutil.copy(os.path.join(IMAGE_POOL_PATH, image_name), os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'testB', image_name))\n",
    "        elif image_info['day_night'] == 'night':\n",
    "            if random.random() < TRAIN_TEST_SPLIT_RATIO:\n",
    "                shutil.copy(os.path.join(IMAGE_POOL_PATH, image_name), os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'trainA', image_name))\n",
    "            else:\n",
    "                shutil.copy(os.path.join(IMAGE_POOL_PATH, image_name), os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'testA', image_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aj.'s dataset (AJDATASET02)\n",
    "\n",
    "- from VDO `2021_0607_184742_013.MOV` and `Top.MOV`\n",
    "- which random select 150 images of each day and night to train\n",
    "- random select 50 images of each day and night to test\n",
    "\n",
    "*observation : those 2 VDOs has the image structure very similar so I decided to merge them together.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup constant parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_POOL_PATH = 'E:/indiv_vdo/extracted/image_pool/'\n",
    "IMAGE_INFO_DICT_PATH = 'E:/indiv_vdo/extracted/dict/info_dict.pkl'\n",
    "\n",
    "TARGET_DATASET_PATH = './datasets'\n",
    "DATASET_NAME = 'AJDATASET02'\n",
    "\n",
    "TRAIN_TEST_SPLIT_RATIO = 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move image to dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info_dict = pickle.load(open(IMAGE_INFO_DICT_PATH, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate dataset structure folder\n",
    "if os.path.exists(os.path.join(TARGET_DATASET_PATH, DATASET_NAME)):\n",
    "    shutil.rmtree(os.path.join(TARGET_DATASET_PATH, DATASET_NAME))\n",
    "for path in [\n",
    "        TARGET_DATASET_PATH,\n",
    "        os.path.join(TARGET_DATASET_PATH, DATASET_NAME),\n",
    "        os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'trainA'),\n",
    "        os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'trainB'),\n",
    "        os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'testA'),\n",
    "        os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'testB')\n",
    "    ]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "copy image: 100%|██████████| 673/673 [00:00<00:00, 807.62image/s]\n"
     ]
    }
   ],
   "source": [
    "night_test_count = 0\n",
    "day_test_count = 0\n",
    "night_train_count = 0\n",
    "day_train_count = 0\n",
    "\n",
    "# copy image from image pool to dataset folder\n",
    "looper = os.listdir(IMAGE_POOL_PATH)\n",
    "random.shuffle(looper)\n",
    "looper = tqdm.tqdm(looper, desc='copy image', unit='image')\n",
    "for image_name in looper:\n",
    "    if image_name in image_info_dict:\n",
    "        image_info = image_info_dict[image_name]\n",
    "        if image_info['day_night'] == 'day':\n",
    "            if random.random() < TRAIN_TEST_SPLIT_RATIO and day_train_count < 150:\n",
    "                shutil.copy(os.path.join(IMAGE_POOL_PATH, image_name), os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'trainB', image_name))\n",
    "                day_train_count += 1\n",
    "            elif day_test_count < 50:\n",
    "                shutil.copy(os.path.join(IMAGE_POOL_PATH, image_name), os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'testB', image_name))\n",
    "                day_test_count += 1\n",
    "        elif image_info['day_night'] == 'night':\n",
    "            if random.random() < TRAIN_TEST_SPLIT_RATIO and night_train_count < 150:\n",
    "                shutil.copy(os.path.join(IMAGE_POOL_PATH, image_name), os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'trainA', image_name))\n",
    "                night_train_count += 1\n",
    "            elif night_test_count < 50:\n",
    "                shutil.copy(os.path.join(IMAGE_POOL_PATH, image_name), os.path.join(TARGET_DATASET_PATH, DATASET_NAME, 'testA', image_name))\n",
    "                night_test_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DATASET_PATH = './datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 dataset in ./datasets/\n",
      "1: AJDATASET01 (4 folders)\n",
      "\ta: testA - 21 images\n",
      "\tb: testB - 7 images\n",
      "\tc: trainA - 169 images\n",
      "\td: trainB - 67 images\n",
      "\t*: Train: 236 images(89.39%)\n",
      "\t*: Test: 28 images(10.61%)\n",
      "2: AJDATASET02 (4 folders)\n",
      "\ta: testA - 40 images\n",
      "\tb: testB - 50 images\n",
      "\tc: trainA - 150 images\n",
      "\td: trainB - 150 images\n",
      "\t*: Train: 300 images(76.92%)\n",
      "\t*: Test: 90 images(23.08%)\n"
     ]
    }
   ],
   "source": [
    "dataset_name_list = os.listdir(TARGET_DATASET_PATH)\n",
    "print(f'There are {len(dataset_name_list)} dataset in {TARGET_DATASET_PATH}')\n",
    "for dataset_idx in range(len(dataset_name_list)):\n",
    "    folder_list = os.listdir(os.path.join(TARGET_DATASET_PATH, dataset_name_list[dataset_idx]))\n",
    "    print(f'{dataset_idx+1}: {dataset_name_list[dataset_idx]} ({len(folder_list)} folders)')\n",
    "    train_image_amt = 0\n",
    "    test_image_amt = 0\n",
    "\n",
    "    for folder_idx in range(len(folder_list)):\n",
    "        image_list = os.listdir(os.path.join(TARGET_DATASET_PATH, dataset_name_list[dataset_idx], folder_list[folder_idx]))\n",
    "        print(f'\\t{chr(ord(\"a\")+folder_idx)}: {folder_list[folder_idx]} - {len(image_list)} images')\n",
    "\n",
    "        if folder_list[folder_idx].startswith('train'):\n",
    "            train_image_amt += len(image_list)\n",
    "        elif folder_list[folder_idx].startswith('test'):\n",
    "            test_image_amt += len(image_list)\n",
    "\n",
    "    print(f'\\t*: Train: {train_image_amt} images({train_image_amt/(train_image_amt+test_image_amt):.2%})')\n",
    "    print(f'\\t*: Test: {test_image_amt} images({test_image_amt/(train_image_amt+test_image_amt):.2%})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
